{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bbc_news.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mindauskas/bbc_news/blob/master/bbc_news.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avRJ8MsC5X1o",
        "colab_type": "code",
        "outputId": "bc34b43d-a502-4cdb-aed3-0173a878216a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "   %tensorflow_version 2.x\n",
        "except Exception:\n",
        "   pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTD3NL3a5jgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SETUP = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzF31qtJ5jkO",
        "colab_type": "code",
        "outputId": "83c4adba-50d0-47f1-b78a-b6c6a7f1c256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "if SETUP:\n",
        "    !pip install -q -U toai==0.2.*\n",
        "    !pip install -q -U nb_black\n",
        "    !pip install -q -U tensorflow-datasets\n",
        "    !pip install -q -U --no-deps tensorflow-addons\n",
        "    !pip install -q -U tensorflow_hub\n",
        "    !pip install -q -U git+https://github.com/huggingface/transformers\n",
        "    print(__import__(\"toai\").__version__)\n",
        "    print(__import__(\"tensorflow\").__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "0.2.7\n",
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeB5eKMK5jp4",
        "colab_type": "code",
        "outputId": "9fd3d213-7275-4f07-f84a-85980230f414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "from toai.imports import *\n",
        "from toai.data import DataBundle, DataParams, DataContainer\n",
        "from toai.metrics import sparse_top_2_categorical_accuracy\n",
        "from toai.models import save_keras_model, load_keras_model\n",
        "from toai.utils import save_file, load_file\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_hub as hub\n",
        "import csv\n",
        "import transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/toai/imports.py:70: UserWarning: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n",
            "  warnings.warn(str(error))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxw46zEFkoso",
        "colab_type": "code",
        "outputId": "31deb939-4825-46bf-f98f-fd8fc51ed627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRDaPKEl5juL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR = Path(\"data/bbc_news\")\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "TEMP_DIR = Path(\"temp/bbc_news\")\n",
        "TEMP_DIR.mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfI-8YSS6giQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if SETUP:\n",
        "    shutil.rmtree(str(DATA_DIR))\n",
        "    shutil.rmtree(str(TEMP_DIR))\n",
        "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    TEMP_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    #shutil.copy(\"bbc_news.pickle\", DATA_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6GGpvmg6gv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 8\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqNHXShH7fJg",
        "colab_type": "text"
      },
      "source": [
        "# **Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lGgEthf7oUB",
        "colab_type": "text"
      },
      "source": [
        "The datset is taken from https://www.kaggle.com/pariza/bbc-news-summary.\n",
        "This dataset for extractive text summarization has four hundred and seventeen political news articles of BBC from 2004 to 2005 in the News Articles folder. For each articles, five summaries are provided in the Summaries folder. The first clause of the text of articles is the respective title."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glej8ZtR6g29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"bbc_news.pickle\", \"rb\") as f:\n",
        "    data = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5dqQ7Xc6g65",
        "colab_type": "code",
        "outputId": "52b950a3-80a7-4a44-9026-49b3f1f13710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 200853 entries, 0 to 200852\n",
            "Data columns (total 6 columns):\n",
            "category             200853 non-null object\n",
            "headline             200853 non-null object\n",
            "authors              200853 non-null object\n",
            "link                 200853 non-null object\n",
            "short_description    200853 non-null object\n",
            "date                 200853 non-null datetime64[ns]\n",
            "dtypes: datetime64[ns](1), object(5)\n",
            "memory usage: 9.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJvAV0Cn6g-V",
        "colab_type": "code",
        "outputId": "22a57674-4a28-4bb8-e9e1-5e500e9db449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "data.describe(include=\"all\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>headline</th>\n",
              "      <th>authors</th>\n",
              "      <th>link</th>\n",
              "      <th>short_description</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>200853</td>\n",
              "      <td>200853</td>\n",
              "      <td>200853</td>\n",
              "      <td>200853</td>\n",
              "      <td>200853</td>\n",
              "      <td>200853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>41</td>\n",
              "      <td>199344</td>\n",
              "      <td>27993</td>\n",
              "      <td>200812</td>\n",
              "      <td>178353</td>\n",
              "      <td>2309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>POLITICS</td>\n",
              "      <td>Sunday Roundup</td>\n",
              "      <td></td>\n",
              "      <td>https://www.huffingtonpost.comhttps://www.wash...</td>\n",
              "      <td></td>\n",
              "      <td>2013-01-17 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>32739</td>\n",
              "      <td>90</td>\n",
              "      <td>36620</td>\n",
              "      <td>2</td>\n",
              "      <td>19712</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>first</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2012-01-28 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>last</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-05-26 00:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        category        headline  ... short_description                 date\n",
              "count     200853          200853  ...            200853               200853\n",
              "unique        41          199344  ...            178353                 2309\n",
              "top     POLITICS  Sunday Roundup  ...                    2013-01-17 00:00:00\n",
              "freq       32739              90  ...             19712                  100\n",
              "first        NaN             NaN  ...               NaN  2012-01-28 00:00:00\n",
              "last         NaN             NaN  ...               NaN  2018-05-26 00:00:00\n",
              "\n",
              "[6 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3q_jSjN6hCZ",
        "colab_type": "code",
        "outputId": "4112464a-fa98-49ad-adee-80f193779bd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "data.head(5).T"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <td>CRIME</td>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>headline</th>\n",
              "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
              "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
              "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
              "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
              "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>authors</th>\n",
              "      <td>Melissa Jeltsen</td>\n",
              "      <td>Andy McDonald</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>Ron Dicker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>link</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>short_description</th>\n",
              "      <td>She left her husband. He killed their children...</td>\n",
              "      <td>Of course it has a song.</td>\n",
              "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
              "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
              "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <td>2018-05-26 00:00:00</td>\n",
              "      <td>2018-05-26 00:00:00</td>\n",
              "      <td>2018-05-26 00:00:00</td>\n",
              "      <td>2018-05-26 00:00:00</td>\n",
              "      <td>2018-05-26 00:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                   0  ...                                                  4\n",
              "category                                                       CRIME  ...                                      ENTERTAINMENT\n",
              "headline           There Were 2 Mass Shootings In Texas Last Week...  ...  Julianna Margulies Uses Donald Trump Poop Bags...\n",
              "authors                                              Melissa Jeltsen  ...                                         Ron Dicker\n",
              "link               https://www.huffingtonpost.com/entry/texas-ama...  ...  https://www.huffingtonpost.com/entry/julianna-...\n",
              "short_description  She left her husband. He killed their children...  ...  The \"Dietland\" actress said using the bags is ...\n",
              "date                                             2018-05-26 00:00:00  ...                                2018-05-26 00:00:00\n",
              "\n",
              "[6 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuOv4-QB6hF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def merge_str(row):\n",
        "  return row['headline'] + '. ' + row['short_description']\n",
        "\n",
        "data[\"merged_text\"] = data.apply(merge_str, axis=1)\n",
        "data = data[['category','merged_text']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Myt96YMHAf3_",
        "colab_type": "code",
        "outputId": "214db9d7-307c-4e56-c787-56e3ea42d5b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "data.iloc[3,:]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "category                                           ENTERTAINMENT\n",
              "merged_text    Jim Carrey Blasts 'Castrato' Adam Schiff And D...\n",
              "Name: 3, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAd54qNiAgXY",
        "colab_type": "code",
        "outputId": "70d39929-030e-4dab-b2aa-3b366fca2326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "data.category.value_counts()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "POLITICS          32739\n",
              "WELLNESS          17827\n",
              "ENTERTAINMENT     16058\n",
              "TRAVEL             9887\n",
              "STYLE & BEAUTY     9649\n",
              "PARENTING          8677\n",
              "HEALTHY LIVING     6694\n",
              "QUEER VOICES       6314\n",
              "FOOD & DRINK       6226\n",
              "BUSINESS           5937\n",
              "COMEDY             5175\n",
              "SPORTS             4884\n",
              "BLACK VOICES       4528\n",
              "HOME & LIVING      4195\n",
              "PARENTS            3955\n",
              "THE WORLDPOST      3664\n",
              "WEDDINGS           3651\n",
              "WOMEN              3490\n",
              "IMPACT             3459\n",
              "DIVORCE            3426\n",
              "CRIME              3405\n",
              "MEDIA              2815\n",
              "WEIRD NEWS         2670\n",
              "GREEN              2622\n",
              "WORLDPOST          2579\n",
              "RELIGION           2556\n",
              "STYLE              2254\n",
              "SCIENCE            2178\n",
              "WORLD NEWS         2177\n",
              "TASTE              2096\n",
              "TECH               2082\n",
              "MONEY              1707\n",
              "ARTS               1509\n",
              "FIFTY              1401\n",
              "GOOD NEWS          1398\n",
              "ARTS & CULTURE     1339\n",
              "ENVIRONMENT        1323\n",
              "COLLEGE            1144\n",
              "LATINO VOICES      1129\n",
              "CULTURE & ARTS     1030\n",
              "EDUCATION          1004\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U54G1ZNJAgiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keep_values(df, col_name, values):\n",
        "    return df.loc[df[col_name].isin(values), :].reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddf1WOPTC8df",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = keep_values(\n",
        "    data, \"category\", data[\"category\"].value_counts()[:15].index\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWu2_Vt6C8qG",
        "colab_type": "code",
        "outputId": "b4b286d9-1410-453b-f52b-678bcd11b8ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "df[\"category\"].value_counts()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "POLITICS          32739\n",
              "WELLNESS          17827\n",
              "ENTERTAINMENT     16058\n",
              "TRAVEL             9887\n",
              "STYLE & BEAUTY     9649\n",
              "PARENTING          8677\n",
              "HEALTHY LIVING     6694\n",
              "QUEER VOICES       6314\n",
              "FOOD & DRINK       6226\n",
              "BUSINESS           5937\n",
              "COMEDY             5175\n",
              "SPORTS             4884\n",
              "BLACK VOICES       4528\n",
              "HOME & LIVING      4195\n",
              "PARENTS            3955\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEUycgdUC8uE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_category_map(labels) -> Dict[str, int]:\n",
        "    return {x: i for i, x in enumerate(sorted(set(labels)))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AACTIHBOC8xO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_category_map(filename, labels):\n",
        "    try:\n",
        "        category_map = load_file(filename)\n",
        "    except:\n",
        "        category_map = make_category_map(labels)\n",
        "        save_file(category_map, filename)\n",
        "    return category_map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arW5lQRqC80Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category_map = init_category_map(\n",
        "    TEMP_DIR / \"category_map.pickle\", df[\"category\"].values\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juxEbdH4C84t",
        "colab_type": "code",
        "outputId": "2d3737e0-8433-423b-9e05-7e6d127dfa94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "category_map"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'BLACK VOICES': 0,\n",
              " 'BUSINESS': 1,\n",
              " 'COMEDY': 2,\n",
              " 'ENTERTAINMENT': 3,\n",
              " 'FOOD & DRINK': 4,\n",
              " 'HEALTHY LIVING': 5,\n",
              " 'HOME & LIVING': 6,\n",
              " 'PARENTING': 7,\n",
              " 'PARENTS': 8,\n",
              " 'POLITICS': 9,\n",
              " 'QUEER VOICES': 10,\n",
              " 'SPORTS': 11,\n",
              " 'STYLE & BEAUTY': 12,\n",
              " 'TRAVEL': 13,\n",
              " 'WELLNESS': 14}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyeZDligEML4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_categories = len(category_map)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8OC6lrhEMVA",
        "colab_type": "code",
        "outputId": "2c5a2c60-1c5b-4507-c8ce-2a6b10aa352c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_categories"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWtseBjaEMaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"category\"] = df[\"category\"].map(category_map)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GuEo_xlEMgl",
        "colab_type": "code",
        "outputId": "a7f3bed7-5a01-47a1-e11b-d2e1360f9d5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "df.category.value_counts()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9     32739\n",
              "14    17827\n",
              "3     16058\n",
              "13     9887\n",
              "12     9649\n",
              "7      8677\n",
              "5      6694\n",
              "10     6314\n",
              "4      6226\n",
              "1      5937\n",
              "2      5175\n",
              "11     4884\n",
              "0      4528\n",
              "6      4195\n",
              "8      3955\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQWFFHaFEMl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data_bundle = DataBundle.from_dataframe(\n",
        "    dataframe=df, x_col=\"merged_text\", y_col=\"category\"\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbGMkMqjEMj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_bundle, validation_data_bundle, test_data_bundle = DataBundle.split(\n",
        "    data_bundle=all_data_bundle, fracs=[0.1, 0.1, 0.1]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP6dkSeAEMed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_container = DataContainer(\n",
        "    train_data_bundle, validation_data_bundle, test_data_bundle\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcYLVsBWLi4y",
        "colab_type": "code",
        "outputId": "991ef6c7-9792-45f5-ce1b-73d5a071045d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "data_container.train.value_counts()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 413,\n",
              " 1: 601,\n",
              " 2: 498,\n",
              " 3: 1618,\n",
              " 4: 624,\n",
              " 5: 660,\n",
              " 6: 446,\n",
              " 7: 837,\n",
              " 8: 420,\n",
              " 9: 3276,\n",
              " 10: 640,\n",
              " 11: 505,\n",
              " 12: 960,\n",
              " 13: 999,\n",
              " 14: 1778}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1l6dSRRLjJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_weights = dict(\n",
        "    enumerate(\n",
        "        sk.utils.class_weight.compute_class_weight(\n",
        "            \"balanced\", np.unique(data_container.train.y), data_container.train.y\n",
        "        )\n",
        "    )\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6Q1qRhkLjWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_container.train = DataBundle.from_unbalanced(data_container.train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H1176aCLjiZ",
        "colab_type": "code",
        "outputId": "d8588b94-1751-4fde-de82-94b3bff83505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "data_container.train.value_counts()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 2891,\n",
              " 1: 3005,\n",
              " 2: 2988,\n",
              " 3: 3236,\n",
              " 4: 3120,\n",
              " 5: 2640,\n",
              " 6: 3122,\n",
              " 7: 2511,\n",
              " 8: 2940,\n",
              " 9: 3276,\n",
              " 10: 3200,\n",
              " 11: 3030,\n",
              " 12: 2880,\n",
              " 13: 2997,\n",
              " 14: 1778}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dX0Gw0iL0i5",
        "colab_type": "code",
        "outputId": "5366bf28-bffc-4829-c96b-b508e990cfae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data_container.train), len(data_container.validation), len(data_container.test)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43614, 14275, 14275)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf3xKTcKL01M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dataset(data_bundle):\n",
        "    return tf.data.Dataset.from_tensor_slices((data_bundle.x, data_bundle.y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qds6qNpL08d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_container.train.dataset = make_dataset(data_container.train)\n",
        "data_container.validation.dataset = make_dataset(data_container.validation)\n",
        "data_container.test.dataset = make_dataset(data_container.test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNrDBpCSL1Cl",
        "colab_type": "code",
        "outputId": "078a230d-c0d8-47ce-a92b-c5e70cf88d99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "data_container.train.x[5]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"This MLK Quote Sums Up The Rise Of White Supremacy Post-Trump. King's words are eerily prophetic.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvI3pAMzL1P4",
        "colab_type": "code",
        "outputId": "ab30e767-2133-43a0-e016-73ad463ffea1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_container.train.y[5]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F-paKUrL1Vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_sentence_length_limiter(limit):\n",
        "    def inner(x, y):\n",
        "        return tf.strings.substr(x, 0, limit), y\n",
        "\n",
        "    return inner"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqFDGQDWL1T0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "length_limiter = make_sentence_length_limiter(300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZxAfzshL1OT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = (\n",
        "    data_container.train.dataset.repeat()\n",
        "    .shuffle(len(data_container.train))\n",
        "    .batch(BATCH_SIZE)\n",
        "    .map(length_limiter)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n",
        "\n",
        "validation_dataset = (\n",
        "    data_container.validation.dataset.batch(BATCH_SIZE)\n",
        "    .map(length_limiter)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqPzIjYoL1Ld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset_steps = math.ceil(len(data_container.train) / BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlSHdz44Py8z",
        "colab_type": "text"
      },
      "source": [
        "## **Tf hub pretrained models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr3GkZUjL1Im",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(\n",
        "    model,\n",
        "    epochs,\n",
        "    lrs=None,\n",
        "    optimizers=None,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    log_dir=str(TEMP_DIR / \"logs\"),\n",
        "):\n",
        "    if optimizers is None:\n",
        "        optimizers = [keras.optimizers.Adam(lr) for lr in lrs]\n",
        "    model.layers[0].trainable = False\n",
        "    model.compile(\n",
        "        loss=keras.losses.sparse_categorical_crossentropy,\n",
        "        optimizer=optimizers[0],\n",
        "        metrics=[\n",
        "            keras.metrics.sparse_categorical_accuracy,\n",
        "            sparse_top_2_categorical_accuracy,\n",
        "        ],\n",
        "    )\n",
        "    model.fit(\n",
        "        train_dataset,\n",
        "        steps_per_epoch=train_dataset_steps,\n",
        "        validation_data=validation_dataset,\n",
        "        epochs=epochs[0],\n",
        "        callbacks=[\n",
        "            keras.callbacks.ReduceLROnPlateau(patience=1, factor=0.3),\n",
        "            keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True),\n",
        "        ],\n",
        "        class_weight=class_weights,\n",
        "        verbose=verbose,\n",
        "    )\n",
        "    model.layers[0].trainable = True\n",
        "    model.compile(\n",
        "        loss=keras.losses.sparse_categorical_crossentropy,\n",
        "        optimizer=optimizers[1],\n",
        "        metrics=[\n",
        "            keras.metrics.sparse_categorical_accuracy,\n",
        "            sparse_top_2_categorical_accuracy,\n",
        "        ],\n",
        "    )\n",
        "    model.fit(\n",
        "        train_dataset,\n",
        "        steps_per_epoch=train_dataset_steps,\n",
        "        validation_data=validation_dataset,\n",
        "        epochs=epochs[1],\n",
        "        callbacks=[\n",
        "            keras.callbacks.ReduceLROnPlateau(patience=patience // 2, factor=0.3),\n",
        "            keras.callbacks.EarlyStopping(patience=patience, restore_best_weights=True),\n",
        "        ],\n",
        "        class_weight=class_weights,\n",
        "        verbose=verbose,\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5D8b2_ML1Gb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_hub_model(url):\n",
        "    return keras.Sequential(\n",
        "        [\n",
        "            hub.KerasLayer(url, dtype=tf.string, input_shape=[]),\n",
        "            keras.layers.Dropout(0.5),\n",
        "            keras.layers.Dense(n_categories, activation=keras.activations.softmax),\n",
        "        ]\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qivZIoTVL1Aa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_models(urls):\n",
        "    for url in urls:\n",
        "        model = make_hub_model(url)\n",
        "        model_name = f\"{url.split('/')[4]}\"\n",
        "        print(f\" {model_name} \".center(80, \"=\"))\n",
        "        shutil.rmtree(str(TEMP_DIR / model_name), ignore_errors=True)\n",
        "        train_model(\n",
        "            model=model,\n",
        "            epochs=[2, 1],\n",
        "            optimizers=[keras.optimizers.Adam(lr=1e-4), keras.optimizers.Adam(lr=3e-5)],\n",
        "            patience=2,\n",
        "            verbose=2,\n",
        "            log_dir=str(TEMP_DIR / model_name),\n",
        "        )\n",
        "        model.save(f\"{TEMP_DIR / model_name}.h5\")\n",
        "        save_keras_model(\n",
        "            model,\n",
        "            str(TEMP_DIR / model_name / \"architecture\"),\n",
        "            str(TEMP_DIR / model_name / \"weights\"),\n",
        "        )\n",
        "        keras.backend.clear_session()\n",
        "        del model\n",
        "        keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL7nghZEL06v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_urls = (\n",
        "    \"https://tfhub.dev/google/Wiki-words-250-with-normalization/2\",\n",
        "    \"https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2\",\n",
        "    \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DgADPX1L0y4",
        "colab_type": "code",
        "outputId": "1fce9477-d921-4775-e1eb-0f75ff9acc12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "run_models(model_urls)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "====================== Wiki-words-250-with-normalization =======================\n",
            "Train for 5452 steps, validate for 1785 steps\n",
            "Epoch 1/2\n",
            "5452/5452 - 31s - loss: 2.5115 - sparse_categorical_accuracy: 0.1969 - sparse_top_2_categorical_accuracy: 0.3267 - val_loss: 2.4318 - val_sparse_categorical_accuracy: 0.3713 - val_sparse_top_2_categorical_accuracy: 0.5150\n",
            "Epoch 2/2\n",
            "5452/5452 - 29s - loss: 2.2903 - sparse_categorical_accuracy: 0.3057 - sparse_top_2_categorical_accuracy: 0.4666 - val_loss: 2.1992 - val_sparse_categorical_accuracy: 0.4062 - val_sparse_top_2_categorical_accuracy: 0.5480\n",
            "Train for 5452 steps, validate for 1785 steps\n",
            "5452/5452 - 371s - loss: 2.0962 - sparse_categorical_accuracy: 0.3901 - sparse_top_2_categorical_accuracy: 0.5634 - val_loss: 2.0560 - val_sparse_categorical_accuracy: 0.4528 - val_sparse_top_2_categorical_accuracy: 0.5960\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2'.\n",
            "INFO:absl:Downloaded https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2, Total size: 483.55MB\n",
            "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/google/nnlm-en-dim128-with-normalization/2'.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "====================== nnlm-en-dim128-with-normalization =======================\n",
            "Train for 5452 steps, validate for 1785 steps\n",
            "Epoch 1/2\n",
            "5452/5452 - 30s - loss: 2.5833 - sparse_categorical_accuracy: 0.1699 - sparse_top_2_categorical_accuracy: 0.2898 - val_loss: 2.5124 - val_sparse_categorical_accuracy: 0.2937 - val_sparse_top_2_categorical_accuracy: 0.4556\n",
            "Epoch 2/2\n",
            "5452/5452 - 29s - loss: 2.3525 - sparse_categorical_accuracy: 0.3161 - sparse_top_2_categorical_accuracy: 0.4891 - val_loss: 2.2649 - val_sparse_categorical_accuracy: 0.4623 - val_sparse_top_2_categorical_accuracy: 0.6104\n",
            "Train for 5452 steps, validate for 1785 steps\n",
            "5452/5452 - 198s - loss: 2.1462 - sparse_categorical_accuracy: 0.4236 - sparse_top_2_categorical_accuracy: 0.6027 - val_loss: 2.1069 - val_sparse_categorical_accuracy: 0.4927 - val_sparse_top_2_categorical_accuracy: 0.6451\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1'.\n",
            "INFO:absl:Downloaded https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1, Total size: 1.69MB\n",
            "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1'.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "================================= tf2-preview ==================================\n",
            "Train for 5452 steps, validate for 1785 steps\n",
            "Epoch 1/2\n",
            "5452/5452 - 29s - loss: 3.2819 - sparse_categorical_accuracy: 0.0954 - sparse_top_2_categorical_accuracy: 0.1777 - val_loss: 2.4293 - val_sparse_categorical_accuracy: 0.2301 - val_sparse_top_2_categorical_accuracy: 0.3509\n",
            "Epoch 2/2\n",
            "5452/5452 - 28s - loss: 2.6054 - sparse_categorical_accuracy: 0.1713 - sparse_top_2_categorical_accuracy: 0.2915 - val_loss: 2.2067 - val_sparse_categorical_accuracy: 0.3313 - val_sparse_top_2_categorical_accuracy: 0.4597\n",
            "Train for 5452 steps, validate for 1785 steps\n",
            "5452/5452 - 33s - loss: 2.4312 - sparse_categorical_accuracy: 0.2100 - sparse_top_2_categorical_accuracy: 0.3458 - val_loss: 2.1784 - val_sparse_categorical_accuracy: 0.3428 - val_sparse_top_2_categorical_accuracy: 0.4719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KOgPw0MP9Gu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "984e2265-735e-48dc-91d0-e1bb2781ecb4"
      },
      "source": [
        "print(\n",
        "    classification_report(\n",
        "        data_container.validation.y, \n",
        "        load_keras_model(\n",
        "            str(TEMP_DIR/model_urls[0].split('/')[4]/'architecture'),\n",
        "            str(TEMP_DIR/model_urls[0].split('/')[4]/'weights'),\n",
        "            custom_objects={'KerasLayer':hub.KerasLayer}\n",
        "        ).predict(data_container.validation.x).argmax(axis=1)))\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.13      0.17       486\n",
            "           1       0.24      0.48      0.32       601\n",
            "           2       0.32      0.22      0.26       521\n",
            "           3       0.45      0.70      0.55      1589\n",
            "           4       0.48      0.79      0.60       615\n",
            "           5       0.22      0.25      0.23       706\n",
            "           6       0.29      0.66      0.40       434\n",
            "           7       0.22      0.41      0.29       880\n",
            "           8       0.16      0.32      0.21       389\n",
            "           9       0.81      0.67      0.73      3289\n",
            "          10       0.47      0.31      0.37       623\n",
            "          11       0.46      0.53      0.49       502\n",
            "          12       0.88      0.35      0.50       963\n",
            "          13       0.69      0.45      0.55       979\n",
            "          14       0.00      0.00      0.00      1698\n",
            "\n",
            "    accuracy                           0.45     14275\n",
            "   macro avg       0.40      0.42      0.38     14275\n",
            "weighted avg       0.47      0.45      0.44     14275\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rctSIs9hMeyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "4110f31a-aaef-4b63-db46-13592bc963e6"
      },
      "source": [
        "print(\n",
        "    classification_report(\n",
        "        data_container.validation.y, \n",
        "        load_keras_model(\n",
        "            str(TEMP_DIR/model_urls[1].split('/')[4]/'architecture'),\n",
        "            str(TEMP_DIR/model_urls[1].split('/')[4]/'weights'),\n",
        "            custom_objects={'KerasLayer':hub.KerasLayer}\n",
        "        ).predict(data_container.validation.x).argmax(axis=1)))\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.19      0.22       486\n",
            "           1       0.30      0.54      0.38       601\n",
            "           2       0.25      0.36      0.29       521\n",
            "           3       0.51      0.67      0.58      1589\n",
            "           4       0.48      0.87      0.62       615\n",
            "           5       0.22      0.29      0.25       706\n",
            "           6       0.39      0.77      0.51       434\n",
            "           7       0.24      0.49      0.32       880\n",
            "           8       0.20      0.34      0.25       389\n",
            "           9       0.82      0.72      0.77      3289\n",
            "          10       0.52      0.25      0.34       623\n",
            "          11       0.71      0.46      0.56       502\n",
            "          12       0.89      0.55      0.68       963\n",
            "          13       0.85      0.45      0.59       979\n",
            "          14       0.00      0.00      0.00      1698\n",
            "\n",
            "    accuracy                           0.49     14275\n",
            "   macro avg       0.44      0.46      0.42     14275\n",
            "weighted avg       0.51      0.49      0.48     14275\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA5wuWOaNIGE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "3fc0e052-f555-45ad-b6f0-2b84cd69137c"
      },
      "source": [
        "print(\n",
        "    classification_report(\n",
        "        data_container.validation.y, \n",
        "        load_keras_model(\n",
        "            str(TEMP_DIR/model_urls[2].split('/')[4]/'architecture'),\n",
        "            str(TEMP_DIR/model_urls[2].split('/')[4]/'weights'),\n",
        "            custom_objects={'KerasLayer':hub.KerasLayer}\n",
        "        ).predict(data_container.validation.x).argmax(axis=1)))\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.08      0.11      0.09       486\n",
            "           1       0.21      0.17      0.19       601\n",
            "           2       0.15      0.18      0.16       521\n",
            "           3       0.34      0.56      0.42      1589\n",
            "           4       0.31      0.54      0.39       615\n",
            "           5       0.14      0.23      0.18       706\n",
            "           6       0.18      0.28      0.22       434\n",
            "           7       0.19      0.46      0.27       880\n",
            "           8       0.08      0.11      0.09       389\n",
            "           9       0.78      0.64      0.70      3289\n",
            "          10       0.17      0.10      0.13       623\n",
            "          11       0.34      0.43      0.38       502\n",
            "          12       0.42      0.03      0.06       963\n",
            "          13       0.56      0.26      0.36       979\n",
            "          14       0.33      0.00      0.00      1698\n",
            "\n",
            "    accuracy                           0.34     14275\n",
            "   macro avg       0.29      0.27      0.24     14275\n",
            "weighted avg       0.40      0.34      0.33     14275\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqiZIGH_NrNm",
        "colab_type": "text"
      },
      "source": [
        "## **BERT model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pTwvVWxVE18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_bert_dataset(data_bundle, tokenizer, sequence_length):\n",
        "    features = tf.data.Dataset.from_tensor_slices(\n",
        "        [\n",
        "            np.pad(\n",
        "                tokenizer.encode(x, add_special_tokens=True),\n",
        "                (0, sequence_length),\n",
        "                \"constant\",\n",
        "                constant_values=tokenizer.pad_token_id,\n",
        "            )[:sequence_length]\n",
        "            for x in data_bundle.x\n",
        "        ]\n",
        "    )\n",
        "    labels = tf.data.Dataset.from_tensor_slices(data_bundle.y)\n",
        "    dataset = tf.data.Dataset.zip((features, labels)).map(\n",
        "        lambda x, y: (\n",
        "            {\n",
        "                \"input_ids\": x,\n",
        "                \"attention_mask\": int(x != tokenizer.pad_token_id),\n",
        "                \"token_type_ids\": int(x >= tokenizer.pad_token_id),\n",
        "            },\n",
        "            y,\n",
        "        ),\n",
        "        num_parallel_calls=AUTOTUNE,\n",
        "    )\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbRFM6RnVFVI",
        "colab_type": "code",
        "outputId": "e62b47cb-7fae-4c87-b950-ea3c476f5433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "config = transformers.BertConfig.from_pretrained(\n",
        "    \"bert-base-cased\", num_labels=n_categories\n",
        ")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 313/313 [00:00<00:00, 216708.01B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBSluvnGVFsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cg2rygNVF6g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62fa83a8-d97d-4c80-ce09-323c8e433336"
      },
      "source": [
        "train_bert_dataset = (\n",
        "    make_bert_dataset(data_container.train, tokenizer, 128)\n",
        "    .repeat()\n",
        "    .shuffle(len(data_container.train))\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.Variable:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.Variable:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.Variable:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.Variable:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.Variable:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.Variable:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.Variable:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.Variable:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.Variable:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.Variable:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.Variable:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.Variable:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsHB269WWMUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_bert_dataset = (\n",
        "    make_bert_dataset(data_container.validation, tokenizer, 128)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OByohbuFWMv_",
        "colab_type": "code",
        "outputId": "c50d4603-fc92-4753-e164-826168f21789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = transformers.TFBertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-cased\", config=config\n",
        ")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 526681800/526681800 [00:10<00:00, 50255104.55B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK7xxLsEWM9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.layers[0].trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKv9X-YlWNPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(lr=1e-5),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy(\"accuracy\")],\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVbo95eoWNJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model_bert(\n",
        "    model,\n",
        "    epochs,\n",
        "    train_dataset,\n",
        "    train_dataset_steps,\n",
        "    validation_dataset,\n",
        "    lrs=None,\n",
        "    optimizers=None,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    log_dir=str(TEMP_DIR / \"bert/logs\"),\n",
        "):\n",
        "    model.layers[0].trainable = False\n",
        "    if optimizers is None:\n",
        "        optimizers = [keras.optimizers.Adam(lr) for lr in lrs]\n",
        "    model.compile(\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer=optimizers[0],\n",
        "        metrics=[\n",
        "            keras.metrics.sparse_categorical_accuracy,\n",
        "            sparse_top_2_categorical_accuracy,\n",
        "        ],\n",
        "    )\n",
        "    model.fit(\n",
        "        train_dataset,\n",
        "        steps_per_epoch=train_dataset_steps,\n",
        "        validation_data=validation_dataset,\n",
        "        epochs=epochs[0],\n",
        "        callbacks=[\n",
        "            keras.callbacks.ReduceLROnPlateau(patience=1, factor=0.3),\n",
        "            keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True),\n",
        "        ],\n",
        "        class_weight=class_weights,\n",
        "        verbose=verbose,\n",
        "    )\n",
        "    model.layers[0].trainable = True\n",
        "    model.compile(\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer=optimizers[1],\n",
        "        metrics=[\n",
        "            keras.metrics.sparse_categorical_accuracy,\n",
        "            sparse_top_2_categorical_accuracy,\n",
        "        ],\n",
        "    )\n",
        "    model.fit(\n",
        "        train_dataset,\n",
        "        steps_per_epoch=train_dataset_steps,\n",
        "        validation_data=validation_dataset,\n",
        "        epochs=epochs[1],\n",
        "        callbacks=[\n",
        "            keras.callbacks.ReduceLROnPlateau(patience=patience // 2, factor=0.3),\n",
        "            keras.callbacks.EarlyStopping(patience=patience, restore_best_weights=True),\n",
        "            keras.callbacks.TensorBoard(log_dir=log_dir),\n",
        "        ],\n",
        "        class_weight=class_weights,\n",
        "        verbose=verbose,\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqHCnrU0XFpn",
        "colab_type": "code",
        "outputId": "e6ce87c0-da5a-46a6-ea24-8bba881bd0ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "train_model_bert(\n",
        "    model=model,\n",
        "    epochs=[2, 1],\n",
        "    train_dataset=train_bert_dataset,\n",
        "    train_dataset_steps=train_dataset_steps // 5,\n",
        "    validation_dataset=validation_bert_dataset,\n",
        "    optimizers=[keras.optimizers.Adam(lr=1e-5), keras.optimizers.Adam(lr=1e-6)],\n",
        "    patience=2,\n",
        "    verbose=2,\n",
        ")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 1090 steps, validate for 1785 steps\n",
            "Epoch 1/2\n",
            "1090/1090 - 210s - loss: 2.6879 - sparse_categorical_accuracy: 0.0961 - sparse_top_2_categorical_accuracy: 0.1884 - val_loss: 2.8008 - val_sparse_categorical_accuracy: 0.0360 - val_sparse_top_2_categorical_accuracy: 0.0761\n",
            "Epoch 2/2\n",
            "1090/1090 - 186s - loss: 2.6103 - sparse_categorical_accuracy: 0.1351 - sparse_top_2_categorical_accuracy: 0.2579 - val_loss: 2.8139 - val_sparse_categorical_accuracy: 0.0965 - val_sparse_top_2_categorical_accuracy: 0.1626\n",
            "Train for 1090 steps, validate for 1785 steps\n",
            "1090/1090 - 320s - loss: 2.4725 - sparse_categorical_accuracy: 0.2236 - sparse_top_2_categorical_accuracy: 0.3678 - val_loss: 2.2502 - val_sparse_categorical_accuracy: 0.3282 - val_sparse_top_2_categorical_accuracy: 0.5212\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}